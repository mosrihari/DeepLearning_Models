{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2kxy0MDr5uc"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, Reshape, BatchNormalization,\\\n",
        "                                    Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KmnG05hsKGS"
      },
      "source": [
        "# CONSTANTS\n",
        "rows, cols = (28, 28)\n",
        "channels = 1\n",
        "img_shape = (rows, cols, channels)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOFPeVdDuqfW"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiJku8Ypsgqf"
      },
      "source": [
        "def build_generator():\n",
        "\n",
        "    noise_shape = (100,)     \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(256, input_shape=noise_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    \n",
        "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
        "    model.add(Reshape(img_shape))\n",
        "    noise = Input(shape=noise_shape)\n",
        "    img = model(noise)    #Generated image\n",
        "\n",
        "    return Model(noise, img)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "judxLOjltb8s"
      },
      "source": [
        "generator = build_generator()"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4MDW7DPtd7M"
      },
      "source": [
        "def build_discriminator():\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Flatten(input_shape=img_shape))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    img = Input(shape=img_shape)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)\n"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iKQpuINAenv"
      },
      "source": [
        "discriminator = build_discriminator()"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_jy5e1iugUg"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvH270W99KIC"
      },
      "source": [
        "optimizer = Adam(0.0002, 0.5)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BGECDMI236x"
      },
      "source": [
        "generator.compile(optimizer=optimizer,loss=\"binary_crossentropy\")\n",
        "discriminator.compile(optimizer=optimizer,loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
        "input_noise = Input(shape=(100,))\n",
        "fake_img = generator(input_noise)\n",
        "validity = discriminator(fake_img)\n",
        "combined = Model(input_noise, validity)\n",
        "combined.compile(optimizer=optimizer, loss=\"binary_crossentropy\")"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKoDA_Vm7rxp"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def save_imgs(epoch):\n",
        "\n",
        "  root_dir = \"/content/drive/MyDrive/DeepLearning_Models/GAN/epochs_image\"\n",
        "  try:\n",
        "    os.mkdir(root_dir)\n",
        "  except:\n",
        "    print(\"Folder exists\")\n",
        "  \n",
        "  r,c = 2,2\n",
        "  noise = np.random.normal(0,1,(r*c, 100))\n",
        "  gen_imgs = generator.predict(noise)\n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(r, c)\n",
        "  cnt = 0\n",
        "  for i in range(r):\n",
        "      for j in range(c):\n",
        "          axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "          axs[i,j].axis('off')\n",
        "          cnt += 1\n",
        "  fig.savefig(f\"{root_dir}/mnist_{epoch}.png\")\n",
        "  plt.close()\n",
        "  return"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_le87nGuodP"
      },
      "source": [
        "def train(epochs = 10000, batch_size = 128, save_every = 2000):\n",
        "  (X_train, _), (_, _) = mnist.load_data()\n",
        "  X_train = (X_train.astype(\"float\") - 127.5) / 127.5   # This is to normalize the image between 0 to 1\n",
        "  half_batch = int(batch_size / 2)\n",
        "  X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "  for epoch in range(1,epochs+1):\n",
        "\n",
        "    # TRAIN DISCRIMINATOR\n",
        "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "    img = X_train[idx]  # real image from the dataset\n",
        "\n",
        "    # Noise\n",
        "    noise = np.random.normal(0, 1, (half_batch, 100)) # input to generator\n",
        "    fake_image = generator.predict(noise) # fake image from GENERATOR\n",
        "\n",
        "    # Discriminator training  np.ones-real image np.zeros-fake image\n",
        "    d_loss_real = discriminator.train_on_batch(img, np.ones((half_batch,1)))\n",
        "    d_loss_fake = discriminator.train_on_batch(fake_image, np.zeros((half_batch,1)))\n",
        "\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # TRAIN GENERATOR\n",
        "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "    y = np.array([1] * batch_size)\n",
        "    g_loss = combined.train_on_batch(noise, y)\n",
        "\n",
        "    if((epoch % save_every) == 0):\n",
        "      print(f\"saved {epoch}\")\n",
        "      save_imgs(epoch)\n",
        "\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx4K1X3u5JiE",
        "outputId": "b9c87ea1-e56f-408c-82ac-0e3ea5a5cc06"
      },
      "source": [
        "train()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saved 2000\n",
            "Folder exists\n",
            "saved 4000\n",
            "Folder exists\n",
            "saved 6000\n",
            "Folder exists\n",
            "saved 8000\n",
            "Folder exists\n",
            "saved 10000\n",
            "Folder exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNlP6KFyLdfQ"
      },
      "source": [
        "root_dir = \"/content/drive/MyDrive/DeepLearning_Models/GAN/\""
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mLLrNzF5d39"
      },
      "source": [
        "generator.save(root_dir+\"generator.h5\")"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_ft8sKLLpmE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}